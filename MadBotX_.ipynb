{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Madhusudan3223/MadBotX-AI-Chatbot/blob/main/MadBotX_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrmJZobH1IcC"
      },
      "source": [
        "# ü§ñ MadBotX: Real-Time AI Chatbot with Hugging Face Zephyr\n",
        "\n",
        "MadBotX is a lightweight, interactive AI chatbot built using Hugging Face's powerful **Zephyr-7B** model. It allows users to have real-time, human-like conversations directly in a web interface using **Gradio** ‚Äî all without needing any external paid API!\n",
        "\n",
        "## üîó MadBotX Chatbot on Hugging Face Spaces\n",
        "[Click here to open MadBotX](https://huggingface.co/spaces/madhumandal/MadBotX)\n",
        "\n",
        "## üöÄ Features\n",
        "\n",
        "- üîç **Conversational AI** using `HuggingFaceH4/zephyr-7b-alpha`\n",
        "- ‚ö° **Accelerated performance** with `torch_dtype=auto` and `device_map=auto`\n",
        "- üåê **Web UI** powered by Gradio ChatInterface\n",
        "- üß† **Context-aware replies** with user-assistant memory\n",
        "- ‚òÅÔ∏è **Deployable on Hugging Face Spaces** for free public access\n",
        "\n",
        "## üñ•Ô∏è UI & Interaction\n",
        "\n",
        "The app uses **Gradio‚Äôs ChatInterface**, which:\n",
        "- Keeps a history of user & assistant turns\n",
        "- Automatically formats prompts\n",
        "- Provides a clean and responsive frontend"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL9d3lhb1X9Y"
      },
      "source": [
        "üì¶ Install Dependencies & Authenticate with Hugging Face\n",
        "Before running the chatbot, we need to install the required libraries and authenticate with the Hugging Face Hub to access the Zephyr model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bO5tNTd9b2-G"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install transformers accelerate gradio --quiet\n",
        "\n",
        "# Login to Hugging Face\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "# Paste your token here\n",
        "login(userdata.get(\"HF_TOKEN_ID\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jULqRYKv1r-h"
      },
      "source": [
        "üß† GPU Availability Check\n",
        "Before running the Zephyr model for real-time inference, it's important to check whether a GPU is available. This block uses PyTorch to confirm GPU access, which speeds up model inference significantly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiinGgEZwh7F",
        "outputId": "f077b446-876d-4bd7-dcdb-1be06439688c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU is available.\n",
            "Device name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is available.\")\n",
        "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"GPU is not available.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DoX3I_F2ANX"
      },
      "source": [
        "ü§ñ Load Zephyr Chat Model\n",
        "This block loads the Zephyr 7B Alpha model using Hugging Face's transformers pipeline. It enables real-time conversational AI directly in Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598,
          "referenced_widgets": [
            "0924d5cfe39c463c80f2f278f5e93c02",
            "8b9dccb369b74a3ca0d65377996206ec",
            "b199b6f606164f149e6e4c0f435a8b06",
            "1c4ee272df9d4335aa733e838aed965c",
            "3fe3427bc7fc44719c6feda091bf3420",
            "461c632fe75b4093affe249914f71c14",
            "3226c97fc07d478cbff3b370c598668d",
            "819351ac9d4a4c33a574601a71e55b84",
            "e8b85bc4481d442c91055881e0b7073b",
            "74134fe8b59f49c891e44301b66ad5b3",
            "513bbc56f6044f9095d5b6e7a825a6bf",
            "6b1d748101a4457581e0c79cecfc5efa",
            "7afef3a6cc2e4a4eaca8989904f27990",
            "0e8bd9ff80c54c0b8aad6f7dbbf8961b",
            "269bc44316c543a8aede51d7ca08905f",
            "0e77164a096e4993987b666b998ceaff",
            "6f4997942165415d88675b096ac49ad1",
            "110b0afe67844e54a631fd1cc170c8e2",
            "dc3fa9ebecca4514a4a44d38404b91c6",
            "dcc06f7ae31c41c9a8bf93cf4cf21c8a",
            "8d3d149a4e5b437599d9bc0e1e328d1a",
            "6205fd935a6b4a909426139f504bd5a7",
            "ad9acb7ffcd04489ad81eefdd55984bb",
            "02c67f0f9ee142a8a71b81a8d1c8734a",
            "038a05ca99f041f88261e895002b1376",
            "d15e1224ea5246a2b6a26e26f3be17a2",
            "8608e10fa6c245f99e70da42b0ab6184",
            "9aa66e20890e44a0ac399a32aa279f22",
            "56a176f3f8624266a5e82058c1483dfd",
            "551ee0f6d5fc4793ba557b486c81bc42",
            "2e31c9c124eb4a56818dffefde808964",
            "98def02f766d40d28bccbf3205629bd6",
            "45cd4e9034cd471693e9a67355a22716",
            "799d50a27a314134bc64b6abaa49d39c",
            "27dddb6b1e5546998ac0aedc8e1655f0",
            "c839cfef2af34e48ac1e823255a1321f",
            "f748b1204ddc42e286fc2148c94c04f3",
            "e0544992c0f349f18bd5dfa038b347c8",
            "2653db60a44241a7b068addc3628ea76",
            "6e19c801d42e4c409dbc5d4571047568",
            "8690dfb422194791b35eed3360635079",
            "cebe780e31794d6fb6c1b1d29fdbda1d",
            "a096d15edfe746a88040874fae9c744b",
            "10935f1909f248189247ae7876ea34a3",
            "c8d383dfb1c545b9bba7aef3c7999523",
            "5ce823f067f54572b792233368cb2326",
            "eac9692700a546039e224fe7f2b57234",
            "6c1df865f8ff44cd967cf9cb70b8fb13",
            "41b29d15f55f43a8ba9fd7da4f639b42",
            "3f04c1e52baa4c0b9de7b361b8b9eece",
            "3d78920284c54f38a975a3b7cb9dc914",
            "7eebe65b6ed44e55be5fbc3282b6cbfc",
            "cf8ca4142260488fb08d3b0e8dd514ac",
            "6adb30428340427ba22cb9a535eda302",
            "1f932aeb8d4e4b89893305dacbec5db2",
            "9cc63e28adbc44c9b1cd2bd47c798490",
            "f9ff7e943dd940e68b28ec56231831c8",
            "a2deadb691314d24afb88ff230eab854",
            "6c639d9faf204aa9a021b74441ca72a1",
            "4e86a97f2d084d409903cfc4b6411257",
            "4ecf9c6393df47968d87f963766ee2da",
            "4c273861f9c3474dbded9ed6a76ad6f8",
            "ae94c09d72cb481c84a24a91c6cc2cfe",
            "af5b1b05022e4dee8126556cec260376",
            "0c4723f300e84b658bb3e2a9ecd37ed8",
            "3c850d6cda9e41e38df731740e8c085a",
            "6d14e7283e3943f08ea9ae6030d646e2",
            "31360b38898a42d89e6cb73b0df9c875",
            "36fef93b8f044c5688ff8a3ad948291e",
            "8d022861500e4be7abc442121b9c8e8d",
            "34eadb2c5cc748009aee678cf9691266",
            "3ffff9c113504a86836d8b0d2ce1f895",
            "84fb6627d2314da3afc847592b6b6cbf",
            "0ab8d6f4a28343ad858731129fea3939",
            "f6823d6d98384c4d9aeba78aad0a4917",
            "7acf31bdee764921ad1697125ca626e2",
            "b74d23117c8f43e28e622e75296322e4",
            "a80980fa84634b3da23acd87cf67b2f5",
            "6fda4e681a33454d8d674658faadb63c",
            "7448c9041aa34e1881c6add6ab3de2b5",
            "f0004dc6cde14d138630a55d7559e423",
            "5785353811a745bbab2203449d07e0ff",
            "d1e25ecc07d147f19a6e7d8526fc47f5",
            "9d84c60f761443bfa45f802b9930aaca",
            "0227a96c2fa5453b904bba32ec7bee66",
            "f970631000fa4c69ba79c58647f291a5",
            "c1d28ee0cacf44ba9de1601ee910759d",
            "20700aa6fd4642de9db7bf9ecee8c038",
            "b891d4bf7dac41c585f04d44ca77cd2b",
            "fa7a2c98f1ff4ee890bde765235d5ed7",
            "ba94f74136f94bcdb4e2737dd0c2daf8",
            "c7c3c2d600784354aa887b03c4b6c284",
            "8097219efda948e4a15163b73be7204f",
            "ad3ee70825f54893a5260c1c64191515",
            "5796ddcc5c2048a8b012275a93c7fe45",
            "a575810e5efd492fbc644ac2afcca53f",
            "42a76083da7c45e08611562baad6e197",
            "a7aadf6f7ee24d7a98bf011c09e8d7e4",
            "2532c8429f914c3593d62ba0e4e8c8c5",
            "35347bb2b04140bda116f9cdd71644ae",
            "1b0c4c3214f840e28793c68c0f6693c7",
            "e767f70392c24170ae9242dba6476d3e",
            "5bfa0dc75bd143158c6089bac4e81d45",
            "089d18553bd740458abf67247b3d35e7",
            "0807ed96f3b0466293cbb68fd0294663",
            "62b6faeba9bd4c4b9d0665d6e5071eb7",
            "1b7318c6f3784a7cb35a87fc492abede",
            "8e9eb90a83344c1aa27152d9fcc875bd",
            "c3be57df8cb0422095bbe816aeada63d",
            "23c5e3724d554f319d21a260a2b0f907",
            "c33c539dd0434723a0831355dc5beb3f",
            "4a0bcca655214d53b145fac1006579ce",
            "3ccaa3a9f0da497382edb911d4e296e6",
            "961f68357f1c4cd39d6bfd9258457ccc",
            "d46d68044d604ae1809176554c4a1216",
            "e8d7c008f3214dc59d3ae47b719551ad",
            "23e7331d98f84f9cb9ea41d50b9e1765",
            "768ea48491604515bd974d4c44c1822e",
            "c6fb183dc00740c793adeb4dd981d8fd",
            "2122e7e75e79476fa0e6dce04673c258",
            "3b0be66b9e7d4807b0ac5bb396a33145",
            "c5ad467b1f3f47639a8cee115f996993",
            "6211d7f3630b4637a023a5ca6fee7c1b",
            "638b5ac9d3c849c49f4df83e5b2aac7c",
            "fac27ad8ce674fdf8abfd967d0ef16a7",
            "1ea44c9b8ce8446ca02f60e11eabdfb5",
            "b3f57301d58a403998e8b4d54c7647fc",
            "d9005e92208e43f0b34836136928f22a",
            "3941e685937b49d6ae1f04b56b18abad",
            "e56e3185d03b4f568510b35c18d0293e",
            "52db242388ee43df9f66915a9e7d527e",
            "9f13af0610dc430e926fb01aeca4d9fd",
            "f4a6f5a50edc46ca974e136ee2928b0a",
            "57dca0b737a747eabbd6944987e64941",
            "ae25d2f9ac0343d6b20bb3ab94fe6704",
            "b0b9da52754249a0874fc2b08c92e8c6",
            "a87b0e81b903417daf1bf300019ecf32",
            "30f6ab0976a2454a9abea6738aa0563c",
            "72637c024c894f28af774f9fa23df854",
            "53e24ef2dd464a3c8e5de0cd5001b28b",
            "63693b319c0b4b64a9e5928897c74408",
            "cddd41cec5f3449699f484f08441b874",
            "d369c419c7894a51be6f6fab0daccc95",
            "0bdf794c07ac4c6ca46e008e2c901bb0",
            "e89856b9908846f587cf30632b9bdc9a",
            "f3e8a0f20db84faf81fc60d1ef8433ad",
            "4ff4cb3cc77b4e03baf4fb9619da6a9d",
            "c204a4a4339f4041bb2401b59014dbfc",
            "98d575f7bfea45b388287e18090bda12",
            "66bb68659ccd436bb1815d5533c9d3c1",
            "e643ae71071a4f4b9aa618db2e1f8913",
            "82dc40fb440a462cbfad9a538773ff73",
            "9c3cf2dea6854b68a80fe04d735b3c1e",
            "51052b3304944e7091e18546a403a212",
            "f96f779f61e9430c9e5d350c14e2df28",
            "6b907781deb74f049c3418bcb8c49e00",
            "af095cd4689f45e5b0e3be9495ae5f43",
            "dd1403c923bd4a749c9ae7ffeee82178",
            "11eda19e5c864990b3adc44f53ec6c7a",
            "11a264f8a9e44980877a34341481d2b5",
            "da7f5ccdc2ac4e1292f32422c2c1bbe1",
            "72af7f3e98794ef5bb381582c31d8f43",
            "3a158187408d489cb1d380f7172f6ba1",
            "60b7ae4c045543c5b42583f49d9f6725",
            "ec1c203b51d34fde80f3b2f8041f979e",
            "f6b247032d7d49d7b32ab87ebc816793",
            "87a2fd3ea417400fb202c2ab59aaa7c3",
            "62e8c8b2c5e34159a0463d27864297cb",
            "031cccb2c3954c57a6f5ed840f3204ae",
            "65cc2a5c2e87478c9e6d6e4fd69a4c8b",
            "90934321074346a9aed9ae47ab10afd8",
            "044ce16dfef542ac8161cae918f3abfa",
            "a23fc5d5c63e4aa49efae4b60313f57f",
            "1d9e6f58b0994372a612367818b68a98",
            "a692ef96de644d158acaa9f8b0859b08",
            "d2e09bac8f344ddc821c16e0a3fb52ac"
          ]
        },
        "id": "fMr2V9MpcmM7",
        "outputId": "a6ac581f-7fee-44b8-fb63-48c3cd4600ef"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0924d5cfe39c463c80f2f278f5e93c02",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 8 files:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b1d748101a4457581e0c79cecfc5efa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad9acb7ffcd04489ad81eefdd55984bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00005-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "799d50a27a314134bc64b6abaa49d39c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00007-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8d383dfb1c545b9bba7aef3c7999523",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00006-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9cc63e28adbc44c9b1cd2bd47c798490",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00004-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d14e7283e3943f08ea9ae6030d646e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00008-of-00008.safetensors:   0%|          | 0.00/816M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a80980fa84634b3da23acd87cf67b2f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b891d4bf7dac41c585f04d44ca77cd2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00008.safetensors:   0%|          | 0.00/1.89G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35347bb2b04140bda116f9cdd71644ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c33c539dd0434723a0831355dc5beb3f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5ad467b1f3f47639a8cee115f996993",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4a6f5a50edc46ca974e136ee2928b0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0bdf794c07ac4c6ca46e008e2c901bb0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f96f779f61e9430c9e5d350c14e2df28",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6b247032d7d49d7b32ab87ebc816793",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/168 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### User: What is the capital of France?\n",
            "### Assistant: The capital of France is Paris.\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load chat model\n",
        "chatbot = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"HuggingFaceH4/zephyr-7b-alpha\",\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# Test it with a simple input\n",
        "response = chatbot(\"### User: What is the capital of France?\\n### Assistant:\", max_new_tokens=100)\n",
        "print(response[0]['generated_text'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4vqT4cx2KRV"
      },
      "source": [
        "üí¨ Build Gradio Chatbot Interface (MadBotX)\n",
        "This section creates an interactive chatbot UI using Gradio and integrates it with the Zephyr 7B Alpha model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "qrpuIK1S0v6X",
        "outputId": "fdef2453-244b-44b6-e969-9315844487dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/chat_interface.py:345: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  self.chatbot = Chatbot(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://fbb7b6aed71e3e7929.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://fbb7b6aed71e3e7929.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Format and respond using Zephyr-style prompts\n",
        "def generate_reply(message, history):\n",
        "    prompt = \"\"\n",
        "    for user, bot in history:\n",
        "        prompt += f\"### User: {user}\\n### Assistant: {bot}\\n\"\n",
        "    prompt += f\"### User: {message}\\n### Assistant:\"\n",
        "\n",
        "    result = chatbot(prompt, max_new_tokens=150, do_sample=True, temperature=0.7)\n",
        "    reply = result[0]['generated_text'].split(\"### Assistant:\")[-1].strip()\n",
        "    return reply\n",
        "\n",
        "# Launch interactive Gradio chat\n",
        "gr.ChatInterface(\n",
        "    fn=generate_reply,\n",
        "    title=\"ü§ñ MadBotX\t\",\n",
        "    theme=\"soft\",\n",
        "    description=\"Ask anything in real-time using Hugging Face's Zephyr model!\"\n",
        ").launch(share=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PaGMxVi0wbr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}